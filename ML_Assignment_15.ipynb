{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Recognize the differences between supervised, semi-supervised, and unsupervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The differences between supervised,semi-supervised and unsupervied learning are:\n",
    "->Supervised learning aims to learn a function that, given a sample of data and desired otputs ,approximates a function \n",
    "that maps inputs to outputs.\n",
    "->Semi-supervised learning aims to label unlabeled data points using knowledge learned from a small number of labeled data\n",
    "points.\n",
    "->Unsupervised learning does not have (or need) any labeled outputs,so its goal is to infer the natural structure present \n",
    "within a set of data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Describe in detail any five examples of classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5 Examples of Classification Problems:\n",
    "    \n",
    "Logistic regression:Logistic regression is a supervised learning classification algorithm used to predict the probability \n",
    "of a target variable.It is one of the simplest ML algorithms that can be used for varoius classification problems such as \n",
    "spam detection ,cancer detection etc.\n",
    "\n",
    "Decision trees:A decision tree is a non-parametric supervised learning algorithm, which is utilized for both classification\n",
    "and regression tasks. It has a hierarchical, tree structure, which consists of a root node, branches, internal nodes and \n",
    "leaf nodes.\n",
    "\n",
    "Random forest:Random Forest is one of the most popular and commonly used algorithms by Data Scientists. Random forest is a\n",
    "Supervised Machine Learning Algorithm that is used widely in Classification and Regression problems. It builds decision \n",
    "trees on different samples and takes their majority vote for classification and average in case of regression.\n",
    "\n",
    "XGBoost:XGBoost, which stands for Extreme Gradient Boosting, is a scalable, distributed gradient-boosted decision tree\n",
    "(GBDT) machine learning library. It provides parallel tree boosting and is the leading machine learning library for \n",
    "regression, classification, and ranking problems.\n",
    "\n",
    "Light GBM:Light Gradient Boosted Machine ,or LightGBM for short ,is an open-source library that provides an efficient and \n",
    "effective implementation of the gradient boosting algorithm.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Describe each phase of the classification process in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Process of classification consistsof two phases:\n",
    "    \n",
    "1.Construction of the classifier\n",
    "2.Usage of the classifier\n",
    "\n",
    "A classifier in machine larning is an algorithm that automatically orders data into one or more of a set of \"classes\".One \n",
    "of the most common examples is an email classifier that scans emails to filter them by class label:Spam or Not Spam.\n",
    "    \n",
    "The main goal of the Classification algorithm is to identify the category of a given dataset,and these algorithms are\n",
    "mainly used to predict the output for the categorical data.Multi-class Classifier: If a classification problem has more \n",
    "than two outcomes,then it is called as Multi-class Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Go through the SVM model in depth using various scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Support Vector Machine (SVM) is a supervised machine learning algorithm used for both classification and regression.\n",
    "\n",
    "Support Vectors are simply the coordinates of individual observation.The SVM classifier is a frontier that best segregates\n",
    "the two classes (hyper-plane/line).\n",
    "\n",
    "SVM or Support Vector Machine is a linear model for classifiaction and regression problems.It can solve linear and \n",
    "non-linear problems and work well for many practical problems.The idea of SVM is simple:The algorithm creates a line or a\n",
    "hyperplane which separates the data into classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5. What are some of the benefits and drawbacks of SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The following are some of the benefits and drawbacks of SVM:\n",
    "    \n",
    "->Benifits:\n",
    "i. SVM works relatively well when there is a clear margin of separation between classes.\n",
    "ii. SVM is more effective in high dimensional spaces.\n",
    "iii. SVM is effective in cases where the number of dimensions is greater than the number of samples.\n",
    "iv. SVM is relatively memory efficient.\n",
    "\n",
    "->Drawbacks:\n",
    "i. SVM algorithm is not suitable for large data sets.\n",
    "ii. SVM does not perform very well when the data set has more noise i.e. target classes are overlapping. \n",
    "iii. In cases where the number of features for each data point exceeds the number of training data samples, the SVM will \n",
    "underperform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Go over the kNN model in depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN is the simplest machine learning algorithm to understand and also to explain.It is a versatile algorithm i.e. useful\n",
    "for both classification and regression.It has one big advantages is that KNN has no pre assumption about the data.\n",
    "\n",
    "The abbreviation KNN stands for K-Nearest Neighbour.It is a supervised machine learning algorithm.The algorithm can be \n",
    "used to solve both classification and regression problem statements.The number of nearest neighbours to a new unknown\n",
    "variable that has to be predicted or classified is denoted by the symbol 'K'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Discuss the kNN algorithm's error rate and validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training error here is the error you'll have you input your training set to your KNN as test set.Since your test sample is \n",
    "in the training dataset,it'll choose itself as the closest and never make mistake.For this reason,the training error will \n",
    "be zero when K=1,irrespective of the dataset.\n",
    "\n",
    "kNN produces predictions by looking at the k nearest neighbours of a case x to predict its y,so that's fine.In paticular,\n",
    "the kNN model basically consists of its training cases-but that's the cross validation procedure doesn't care about at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8. For kNN, talk about how to measure the difference between the test and training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN can be used for classification -the output is a class membership (predicts a class-a discrete value).An object is \n",
    "classified by a majority vote of its neighbours ,with the object being assigned to the class most common among its k \n",
    "nearest neighbours.\n",
    "kNN classifier does not have any specialized training phase as it uses all the training samples for classification and\n",
    "simply stores the results in memory.kNN is a non-parametric algorithm because it does not assume anything about the traing\n",
    "data.This makes it useful for problems having non-linear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Create the kNN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "->The k-nearest neighbor algorithm is imported from the scikit-learn package.\n",
    "->Create feature and target variables.\n",
    "->Split data into training and test data.\n",
    "->Generate a k-NN model using neighbors value.\n",
    "->Train or fit the data into the model.\n",
    "->Predict the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10.What is a decision tree, exactly? What are the various kinds of nodes? Explain all in depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A decision tree is a tree-like model that acts as a decision support tool,visually displaying decisions and their potential\n",
    "outcomes,consequences and costs.Drawing a decision tree diagram stats from left to right and consists of burst nodes that \n",
    "split into different paths.\n",
    "\n",
    "There are three different types of nodes :chance nodes,decision nodes and end nodes.A chance node,represented by a circle,\n",
    "shows the probabilities of certain results.A decision node,represented by a square,shows a decision to be made,and an end  \n",
    "node shows the final outcome of a decision path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11. Describe the different ways to scan a decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In a decision tree analysis ,the decision -maker has usually to proceed through the following six steps:\n",
    "\n",
    "->Define the problem in structured terms.\n",
    "->Model the decision process.\n",
    "->Apply the appropriate probability values and financial data.\n",
    "->Solve the decision tree.\n",
    "->Perform sensivity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12. Describe in depth the decision tree algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decision Tree algorithm belongs to the family of supervised learning algorithms.The goal of using a Decision Tree is to \n",
    "create a training model that can use to predict the class or value of the target variable by learning simple decision \n",
    "rules inferred from prior data(training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13. In a decision tree, what is inductive bias? What would you do to stop overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In machine learning, the term inductive bias refers to a set of (explicit or implicit) assumptions made by a learning \n",
    "algorithm in order to perform induction, that is, to generalize a finite set of observation (training data) into a general \n",
    "model of the domain.\n",
    "\n",
    "Overfitting maakes the model relevant to its data set only and irrelevant to any other data sets.Some of the methods used\n",
    "to prevent overfitting include ensembling ,data augmentation ,data simplification and cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "14.Explain advantages and disadvantages of using a decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Advantages and Disadvantages of Decision Trees in Machine Learning .Decision Tree is used to solve both classification and\n",
    "regression problems.But the main drawback of Decision Tree is that it generally leads to overfitting of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "15. Describe in depth the problems that are suitable for decision tree learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decision tree learning is generally best suited to problems with the following characteristics:\n",
    "\n",
    "->Instances are represented by attribute-value pairs. \n",
    "->The target function has discrete output values. \n",
    "->Disjunctive descriptions may be required. \n",
    "->The training data may contain errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16. Describe in depth the random forest model. What distinguishes a random forest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The random forest is a classification algorithm consisting of many decisions trees.It uses bagging and feature randomness \n",
    "when building each indidual tree to try to create an uncorrelated forest of trees whose prediction by committee is more \n",
    "accurate than that of any individual tree.The fundamental difference is that in Random forests,only a subset of features \n",
    "are selected at randomout of the total and the best split feature from the subset is used to split each node in a tree,\n",
    "unlike in bagging where all features are considered for splitting a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "17. In a random forest, talk about OOB error and variable value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The out-of-bag(OOB) error is the average error for each calculated using predictions from the trees that do not contain in\n",
    "their respective bootstrap sample.There are two measures of importance given for each variable in the random forest.The \n",
    "first measure is based on how much the accuracy when the variable is excluded.The second masure is based on the decrease \n",
    "of Gini impurity when a variable is chosen to split a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
