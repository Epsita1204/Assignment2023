{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What is the difference between supervised and unsupervised learning? Give some examples to illustrate your point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The main difference between supervised vs unsupervised learning is the need for labelled training data. Supervised machine \n",
    "learning relies on labelled input and output training data, whereas unsupervised learning processes unlabelled or raw data.\n",
    "\n",
    "In Supervised learning,you train the machine using data which is well \"labeled\".Unsupervised learning is a machine learning\n",
    "technique,where you do not need to supervise the model.For example,Baby can identify other dogs based on past supervised \n",
    "learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Mention a few unsupervised learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The main applications of unsupervised learning include clustering,visualization,dimensionality reduction,finding \n",
    "association rules and anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3. What are the three main types of clustering methods? Briefly describe the characteristics of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The various types of clustering are:\n",
    "    \n",
    "i. Connectivity-baed- clustering(Hierarchical clustering):Hierarchical clustering is an unsupervised learning method for \n",
    "clustering data points. The algorithm builds clusters by measuring the dissimilarities between data. Unsupervised learning \n",
    "means that a model does not have to be trained, and we do not need a \"target\" variable.\n",
    "\n",
    "ii. Centroids-based culstering (Partitioning methods):Centroid-based clustering organizes the data into non-hierarchical \n",
    "clusters, in contrast to hierarchical clustering defined below. k-means is the most widely-used centroid-based clustering \n",
    "algorithm. Centroid-based algorithms are efficient but sensitive to initial conditions and outliers.\n",
    "\n",
    "iii.Density-based Clustering(Model-based methods):Density-Based Clustering refers to unsupervised machine learning methods \n",
    "that identify distinctive clusters in the data, based on the idea that a cluster/group in a data space is a contiguous \n",
    "region of high point density, separated from other clusters by sparse regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Explain how the k-means algorithm determines the consistency of clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculate the Within-Cluster-Sum of Squared Errors(WSS) for different values of k,and choose the k for which WSS becomes\n",
    "first starts to diminish.In the plot of WSS-versus-k, this is visible as an elbow.Within-Cluster-Sum of Squared Errors \n",
    "sounds a bit complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5. With a simple illustration, explain the key difference between the k-means and k-medoids algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K-means attempts to minimize the total squared error, while k-medoids minimizes the sum of dissimilarities between points \n",
    "labeled to be in a cluster and a point designated as the center of that cluster. In contrast to the k -means algorithm, \n",
    "k -medoids chooses datapoints as centers ( medoids or exemplars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6. What is a dendrogram, and how does it work? Explain how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A dendrogram ia a diagram that shows the attribute distances between each pair of sequentially merged classes After each\n",
    "merging ,the distances between all pairs of classes are updated.The distances at which the signatures of classes are merged\n",
    "are used to construct a dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7. What exactly is SSE? What role does it play in the k-means algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sum of squared errors (SSE) is actually the weighted sum of squared errors if the heteroscedastic errors option is not \n",
    "equal to constant variance. The mean squared error (MSE) is the SSE divided by the degrees of freedom for the errors for\n",
    "the constrained model, which is n-2(k+1).\n",
    "\n",
    "The SSE is defined as the sum of the squared Euclidean distances of each point to its closest centroid.Since this is a \n",
    "measure of error,the objective of k-means is to try to minimize this value.The purpose of this figure is to show that the \n",
    "initialization of the centroids is an important step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8. With a step-by-step algorithm, explain the k-means procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K-means is a data clustering approach for unsupervised machine learning that can separate unlabeled data into a \n",
    "predetermined number of disjoint groups of equal variance – clusters – based on their similarities. It's a popular \n",
    "algorithm thanks to its ease of use and speed on large datasets.\n",
    "\n",
    "->Step 1:Choose the number of clusters k.\n",
    "->Step 2:Select k random points from the data as centroids.\n",
    "->Step 3:Assign all the points to the closest cluster centroid.\n",
    "->Step 4:Recompute the centroids of newly formed clusters.\n",
    "->Step 5:Repeat steps 3 and 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9. In the sense of hierarchical clustering, define the terms single link and complete link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In single-link(or single linkage) hierarchical clustering,we merge in each step the two clusters whose two closest members\n",
    "have the smallest distance(or the two clusters with the smallest minimum pairwise distance).Complete-link clustering can\n",
    "also be described using the concept of clique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10. How does the apriori concept aid in the reduction of measurement overhead in a business basket analysis? Give an \n",
    "example to demonstrate your point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apriori algorithm assumes that any subset of a frequent itemset must be frequent. Its the algorithm behind Market Basket \n",
    "Analysis.So, a transaction containing {Grapes, Apple, Mango} also contains {Grapes, Mango}. So, according to the principle\n",
    "of Apriori, if {Grapes, Apple, Mango} is frequent, then {Grapes, Mango} must also be frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
